{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfert Learning avec ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-04 17:33:38.359114: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, RMSprop, Adam, Adadelta\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Charger les images et assigner les labels (ne pas relancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nom_champions_gen = os.listdir('./images_draft')\n",
    "noms_champions_gen_modif = [nom_champions_gen[x][:-6] for x in range(len(nom_champions_gen))]\n",
    "# Enlever .DS\n",
    "noms_champions_gen_modif = [x for x in noms_champions_gen_modif if x != '.DS']\n",
    "print(noms_champions_gen_modif)\n",
    "for champion in noms_champions_gen_modif:\n",
    "    print(champion)\n",
    "   # Create a folder for each champion and move the unique image of the champion in it\n",
    "#    os.mkdir('./images_draft/'+champion)\n",
    "\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move in each folder the file 'the picture\n",
    "print(noms_champions_gen_modif)\n",
    "for champion in noms_champions_gen_modif:\n",
    "    print(champion)\n",
    "    os.rename('./images_draft/'+champion+'_0.jpg', './images_draft/'+champion+'/'+champion+'_0.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each folder in the folder images_draft, create duplicates in order to have 5 pictures per champion\n",
    "for champion in noms_champions_gen_modif:\n",
    "    for i in range(6, 11):\n",
    "        # We don't use rename because we want to keep the original picture\n",
    "        os.system('cp ./images_draft/'+champion+'/'+champion+'_0.jpg ./images_draft/'+champion+'/'+champion+'_'+str(i)+'.jpg')\n",
    "            \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mod√®le effectif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LeeSin', 'Rakan', 'Diana', 'Vayne', 'MasterYi', 'Nilah', 'Sion', 'Zed', 'Talon', 'Akshan', 'Zoe', 'Akali', 'Bard', 'Riven', 'Vi', 'Ashe', 'Syndra', 'Rell', 'Gragas', 'Darius', 'Malzahar', 'Soraka', 'Gwen', 'Graves', 'Qiyana', 'Azir', 'Viego', 'Ahri', 'Kayle', 'Veigar', 'Rammus', 'FiddleSticks', 'Morgana', 'TahmKench', 'Lillia', 'Jinx', 'Thresh', 'Warwick', 'Nasus', 'Fiora', 'Ziggs', 'Nautilus', 'Yasuo', 'Khazix', 'Sylas', 'Ivern', 'Kaisa', 'Shyvana', 'Nami', 'Orianna', 'Ezreal', 'Malphite', 'Mordekaiser', 'Brand', 'Leona', 'Shaco', 'Ryze', 'Nocturne', 'Rengar', 'Kled', 'Senna', 'Varus', 'Jhin', 'Singed', 'MonkeyKing', 'Aatrox', 'Vladimir', 'Belveth', 'Heimerdinger', 'Zilean', 'Skarner', 'Yuumi', 'Samira', 'Lissandra', 'Pantheon', 'Caitlyn', 'Braum', 'Kennen', 'Zac', 'Illaoi', 'Sona', 'Tristana', 'DrMundo', 'Seraphine', 'Viktor', 'Ornn', 'Cassiopeia', 'Garen', 'Yorick', 'Maokai', 'Sivir', 'Zeri', 'Tryndamere', 'Karma', 'Renata', 'Kassadin', 'Katarina', 'Vex', 'Corki', 'Amumu', 'Poppy', 'Trundle', 'Gangplank', 'Elise', 'MissFortune', 'Blitzcrank', 'JarvanIV', 'Quinn', 'Pyke', 'Camille', 'Janna', 'Lucian', 'Teemo', 'Sett', 'Urgot', 'Olaf', 'Gnar', 'Alistar', 'KogMaw', 'Zyra', 'AurelionSol', 'Sejuani', 'Taric', 'Evelynn', 'KSante', 'Kalista', 'Chogath', 'Galio', 'Jayce', 'Rumble', 'Yone', 'Aphelios', 'TwistedFate', 'Anivia', 'Swain', 'XinZhao', 'Ekko', 'Kayn', 'Shen', 'Taliyah', 'RekSai', 'Irelia', 'Nidalee', 'Neeko', 'Xerath', 'Jax', 'Renekton', 'Karthus', 'Twitch', 'Draven', 'Udyr', 'Lulu', 'Hecarim', 'Volibear', 'Velkoz', 'Lux', 'Nunu', 'Leblanc', 'Xayah', 'Fizz', 'Annie', 'Kindred']\n",
      "162\n"
     ]
    }
   ],
   "source": [
    "data_path = \"./images_draft\"\n",
    "data_dir_list = os.listdir(data_path)\n",
    "for x in data_dir_list:\n",
    "    if x == '.DS_Store':\n",
    "        data_dir_list.remove(x)\n",
    "print(data_dir_list)\n",
    "num_classes = len(data_dir_list) \n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows=224\n",
    "img_cols=224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channel=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the images of dataset-LeeSin\n",
      "\n",
      "Loaded the images of dataset-Rakan\n",
      "\n",
      "Loaded the images of dataset-Diana\n",
      "\n",
      "Loaded the images of dataset-Vayne\n",
      "\n",
      "Loaded the images of dataset-MasterYi\n",
      "\n",
      "Loaded the images of dataset-Nilah\n",
      "\n",
      "Loaded the images of dataset-Sion\n",
      "\n",
      "Loaded the images of dataset-Zed\n",
      "\n",
      "Loaded the images of dataset-Talon\n",
      "\n",
      "Loaded the images of dataset-Akshan\n",
      "\n",
      "Loaded the images of dataset-Zoe\n",
      "\n",
      "Loaded the images of dataset-Akali\n",
      "\n",
      "Loaded the images of dataset-Bard\n",
      "\n",
      "Loaded the images of dataset-Riven\n",
      "\n",
      "Loaded the images of dataset-Vi\n",
      "\n",
      "Loaded the images of dataset-Ashe\n",
      "\n",
      "Loaded the images of dataset-Syndra\n",
      "\n",
      "Loaded the images of dataset-Rell\n",
      "\n",
      "Loaded the images of dataset-Gragas\n",
      "\n",
      "Loaded the images of dataset-Darius\n",
      "\n",
      "Loaded the images of dataset-Malzahar\n",
      "\n",
      "Loaded the images of dataset-Soraka\n",
      "\n",
      "Loaded the images of dataset-Gwen\n",
      "\n",
      "Loaded the images of dataset-Graves\n",
      "\n",
      "Loaded the images of dataset-Qiyana\n",
      "\n",
      "Loaded the images of dataset-Azir\n",
      "\n",
      "Loaded the images of dataset-Viego\n",
      "\n",
      "Loaded the images of dataset-Ahri\n",
      "\n",
      "Loaded the images of dataset-Kayle\n",
      "\n",
      "Loaded the images of dataset-Veigar\n",
      "\n",
      "Loaded the images of dataset-Rammus\n",
      "\n",
      "Loaded the images of dataset-FiddleSticks\n",
      "\n",
      "Loaded the images of dataset-Morgana\n",
      "\n",
      "Loaded the images of dataset-TahmKench\n",
      "\n",
      "Loaded the images of dataset-Lillia\n",
      "\n",
      "Loaded the images of dataset-Jinx\n",
      "\n",
      "Loaded the images of dataset-Thresh\n",
      "\n",
      "Loaded the images of dataset-Warwick\n",
      "\n",
      "Loaded the images of dataset-Nasus\n",
      "\n",
      "Loaded the images of dataset-Fiora\n",
      "\n",
      "Loaded the images of dataset-Ziggs\n",
      "\n",
      "Loaded the images of dataset-Nautilus\n",
      "\n",
      "Loaded the images of dataset-Yasuo\n",
      "\n",
      "Loaded the images of dataset-Khazix\n",
      "\n",
      "Loaded the images of dataset-Sylas\n",
      "\n",
      "Loaded the images of dataset-Ivern\n",
      "\n",
      "Loaded the images of dataset-Kaisa\n",
      "\n",
      "Loaded the images of dataset-Shyvana\n",
      "\n",
      "Loaded the images of dataset-Nami\n",
      "\n",
      "Loaded the images of dataset-Orianna\n",
      "\n",
      "Loaded the images of dataset-Ezreal\n",
      "\n",
      "Loaded the images of dataset-Malphite\n",
      "\n",
      "Loaded the images of dataset-Mordekaiser\n",
      "\n",
      "Loaded the images of dataset-Brand\n",
      "\n",
      "Loaded the images of dataset-Leona\n",
      "\n",
      "Loaded the images of dataset-Shaco\n",
      "\n",
      "Loaded the images of dataset-Ryze\n",
      "\n",
      "Loaded the images of dataset-Nocturne\n",
      "\n",
      "Loaded the images of dataset-Rengar\n",
      "\n",
      "Loaded the images of dataset-Kled\n",
      "\n",
      "Loaded the images of dataset-Senna\n",
      "\n",
      "Loaded the images of dataset-Varus\n",
      "\n",
      "Loaded the images of dataset-Jhin\n",
      "\n",
      "Loaded the images of dataset-Singed\n",
      "\n",
      "Loaded the images of dataset-MonkeyKing\n",
      "\n",
      "Loaded the images of dataset-Aatrox\n",
      "\n",
      "Loaded the images of dataset-Vladimir\n",
      "\n",
      "Loaded the images of dataset-Belveth\n",
      "\n",
      "Loaded the images of dataset-Heimerdinger\n",
      "\n",
      "Loaded the images of dataset-Zilean\n",
      "\n",
      "Loaded the images of dataset-Skarner\n",
      "\n",
      "Loaded the images of dataset-Yuumi\n",
      "\n",
      "Loaded the images of dataset-Samira\n",
      "\n",
      "Loaded the images of dataset-Lissandra\n",
      "\n",
      "Loaded the images of dataset-Pantheon\n",
      "\n",
      "Loaded the images of dataset-Caitlyn\n",
      "\n",
      "Loaded the images of dataset-Braum\n",
      "\n",
      "Loaded the images of dataset-Kennen\n",
      "\n",
      "Loaded the images of dataset-Zac\n",
      "\n",
      "Loaded the images of dataset-Illaoi\n",
      "\n",
      "Loaded the images of dataset-Sona\n",
      "\n",
      "Loaded the images of dataset-Tristana\n",
      "\n",
      "Loaded the images of dataset-DrMundo\n",
      "\n",
      "Loaded the images of dataset-Seraphine\n",
      "\n",
      "Loaded the images of dataset-Viktor\n",
      "\n",
      "Loaded the images of dataset-Ornn\n",
      "\n",
      "Loaded the images of dataset-Cassiopeia\n",
      "\n",
      "Loaded the images of dataset-Garen\n",
      "\n",
      "Loaded the images of dataset-Yorick\n",
      "\n",
      "Loaded the images of dataset-Maokai\n",
      "\n",
      "Loaded the images of dataset-Sivir\n",
      "\n",
      "Loaded the images of dataset-Zeri\n",
      "\n",
      "Loaded the images of dataset-Tryndamere\n",
      "\n",
      "Loaded the images of dataset-Karma\n",
      "\n",
      "Loaded the images of dataset-Renata\n",
      "\n",
      "Loaded the images of dataset-Kassadin\n",
      "\n",
      "Loaded the images of dataset-Katarina\n",
      "\n",
      "Loaded the images of dataset-Vex\n",
      "\n",
      "Loaded the images of dataset-Corki\n",
      "\n",
      "Loaded the images of dataset-Amumu\n",
      "\n",
      "Loaded the images of dataset-Poppy\n",
      "\n",
      "Loaded the images of dataset-Trundle\n",
      "\n",
      "Loaded the images of dataset-Gangplank\n",
      "\n",
      "Loaded the images of dataset-Elise\n",
      "\n",
      "Loaded the images of dataset-MissFortune\n",
      "\n",
      "Loaded the images of dataset-Blitzcrank\n",
      "\n",
      "Loaded the images of dataset-JarvanIV\n",
      "\n",
      "Loaded the images of dataset-Quinn\n",
      "\n",
      "Loaded the images of dataset-Pyke\n",
      "\n",
      "Loaded the images of dataset-Camille\n",
      "\n",
      "Loaded the images of dataset-Janna\n",
      "\n",
      "Loaded the images of dataset-Lucian\n",
      "\n",
      "Loaded the images of dataset-Teemo\n",
      "\n",
      "Loaded the images of dataset-Sett\n",
      "\n",
      "Loaded the images of dataset-Urgot\n",
      "\n",
      "Loaded the images of dataset-Olaf\n",
      "\n",
      "Loaded the images of dataset-Gnar\n",
      "\n",
      "Loaded the images of dataset-Alistar\n",
      "\n",
      "Loaded the images of dataset-KogMaw\n",
      "\n",
      "Loaded the images of dataset-Zyra\n",
      "\n",
      "Loaded the images of dataset-AurelionSol\n",
      "\n",
      "Loaded the images of dataset-Sejuani\n",
      "\n",
      "Loaded the images of dataset-Taric\n",
      "\n",
      "Loaded the images of dataset-Evelynn\n",
      "\n",
      "Loaded the images of dataset-KSante\n",
      "\n",
      "Loaded the images of dataset-Kalista\n",
      "\n",
      "Loaded the images of dataset-Chogath\n",
      "\n",
      "Loaded the images of dataset-Galio\n",
      "\n",
      "Loaded the images of dataset-Jayce\n",
      "\n",
      "Loaded the images of dataset-Rumble\n",
      "\n",
      "Loaded the images of dataset-Yone\n",
      "\n",
      "Loaded the images of dataset-Aphelios\n",
      "\n",
      "Loaded the images of dataset-TwistedFate\n",
      "\n",
      "Loaded the images of dataset-Anivia\n",
      "\n",
      "Loaded the images of dataset-Swain\n",
      "\n",
      "Loaded the images of dataset-XinZhao\n",
      "\n",
      "Loaded the images of dataset-Ekko\n",
      "\n",
      "Loaded the images of dataset-Kayn\n",
      "\n",
      "Loaded the images of dataset-Shen\n",
      "\n",
      "Loaded the images of dataset-Taliyah\n",
      "\n",
      "Loaded the images of dataset-RekSai\n",
      "\n",
      "Loaded the images of dataset-Irelia\n",
      "\n",
      "Loaded the images of dataset-Nidalee\n",
      "\n",
      "Loaded the images of dataset-Neeko\n",
      "\n",
      "Loaded the images of dataset-Xerath\n",
      "\n",
      "Loaded the images of dataset-Jax\n",
      "\n",
      "Loaded the images of dataset-Renekton\n",
      "\n",
      "Loaded the images of dataset-Karthus\n",
      "\n",
      "Loaded the images of dataset-Twitch\n",
      "\n",
      "Loaded the images of dataset-Draven\n",
      "\n",
      "Loaded the images of dataset-Udyr\n",
      "\n",
      "Loaded the images of dataset-Lulu\n",
      "\n",
      "Loaded the images of dataset-Hecarim\n",
      "\n",
      "Loaded the images of dataset-Volibear\n",
      "\n",
      "Loaded the images of dataset-Velkoz\n",
      "\n",
      "Loaded the images of dataset-Lux\n",
      "\n",
      "Loaded the images of dataset-Nunu\n",
      "\n",
      "Loaded the images of dataset-Leblanc\n",
      "\n",
      "Loaded the images of dataset-Xayah\n",
      "\n",
      "Loaded the images of dataset-Fizz\n",
      "\n",
      "Loaded the images of dataset-Annie\n",
      "\n",
      "Loaded the images of dataset-Kindred\n",
      "\n",
      "(1620, 224, 224, 3)\n",
      "80.36091\n",
      "63.422024\n",
      "[[[80.24691  76.15432  78.01852 ]\n",
      "  [80.14815  76.30247  78.27161 ]\n",
      "  [80.40124  76.47531  78.53086 ]\n",
      "  ...\n",
      "  [80.419754 72.91358  75.06173 ]\n",
      "  [80.24074  73.265434 74.1358  ]\n",
      "  [79.14815  72.25926  73.512344]]\n",
      "\n",
      " [[80.65432  76.67284  78.82716 ]\n",
      "  [80.74691  76.70988  78.888885]\n",
      "  [81.22222  76.987656 79.22222 ]\n",
      "  ...\n",
      "  [80.77778  73.4321   75.70988 ]\n",
      "  [80.88271  74.09259  74.512344]\n",
      "  [79.765434 73.141975 73.734566]]\n",
      "\n",
      " [[81.       77.51852  79.80247 ]\n",
      "  [81.4321   77.51852  79.81481 ]\n",
      "  [81.5679   77.46914  79.78395 ]\n",
      "  ...\n",
      "  [82.28395  75.0679   77.20988 ]\n",
      "  [81.78395  75.24691  75.580246]\n",
      "  [81.74074  75.0679   75.43827 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[63.030865 58.012344 65.69753 ]\n",
      "  [62.89506  57.88889  65.6358  ]\n",
      "  [64.03086  59.15432  66.32716 ]\n",
      "  ...\n",
      "  [62.580246 58.098766 65.33951 ]\n",
      "  [61.962963 57.814816 64.78395 ]\n",
      "  [61.475307 57.34568  63.91358 ]]\n",
      "\n",
      " [[62.74074  57.320988 65.666664]\n",
      "  [62.5      57.22222  65.234566]\n",
      "  [63.21605  57.987656 65.35185 ]\n",
      "  ...\n",
      "  [62.5679   57.919754 65.19136 ]\n",
      "  [62.290123 57.925926 64.75926 ]\n",
      "  [62.160492 57.796295 64.450615]]\n",
      "\n",
      " [[62.493828 56.91358  65.320984]\n",
      "  [62.944443 57.290123 65.4321  ]\n",
      "  [63.179012 57.271606 64.987656]\n",
      "  ...\n",
      "  [62.660492 58.246914 65.450615]\n",
      "  [61.753086 57.43827  64.20988 ]\n",
      "  [62.12963  57.851852 64.4321  ]]]\n",
      "[[[60.580433 58.18572  59.75059 ]\n",
      "  [60.108547 58.600216 60.26743 ]\n",
      "  [60.09531  58.70524  60.60926 ]\n",
      "  ...\n",
      "  [61.292755 57.709526 60.53811 ]\n",
      "  [61.181602 58.208534 60.305214]\n",
      "  [60.540504 57.183994 59.557583]]\n",
      "\n",
      " [[60.438915 58.47887  60.223537]\n",
      "  [60.137848 58.87667  60.686802]\n",
      "  [60.143158 58.727436 60.634144]\n",
      "  ...\n",
      "  [62.00861  58.245064 61.276073]\n",
      "  [62.388435 58.983383 60.981277]\n",
      "  [61.95065  57.991398 60.06674 ]]\n",
      "\n",
      " [[60.273964 58.35486  60.567463]\n",
      "  [60.322315 58.75803  60.689342]\n",
      "  [60.335693 59.040825 60.79394 ]\n",
      "  ...\n",
      "  [62.772045 59.26152  62.578037]\n",
      "  [62.529182 59.323837 61.3649  ]\n",
      "  [62.69452  58.832314 61.296505]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[52.119736 49.014866 55.68203 ]\n",
      "  [51.95129  49.28897  55.9062  ]\n",
      "  [52.29076  50.229034 55.836224]\n",
      "  ...\n",
      "  [55.59278  54.221775 58.00016 ]\n",
      "  [54.041245 53.145306 56.94029 ]\n",
      "  [53.431698 53.230957 57.081932]]\n",
      "\n",
      " [[52.0382   48.084484 55.881905]\n",
      "  [52.115974 48.095108 55.677956]\n",
      "  [53.424385 50.207817 56.0762  ]\n",
      "  ...\n",
      "  [55.630077 53.866146 58.604794]\n",
      "  [54.02966  53.03293  57.708927]\n",
      "  [54.047733 53.069874 57.76099 ]]\n",
      "\n",
      " [[52.923515 48.746037 56.020077]\n",
      "  [53.28243  49.028877 56.336357]\n",
      "  [54.604374 49.663425 56.515533]\n",
      "  ...\n",
      "  [57.500404 56.002575 59.639755]\n",
      "  [55.454422 54.714947 58.386795]\n",
      "  [55.5343   54.87803  58.960346]]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "img_data_list=[]\n",
    "labels_list = []\n",
    "\n",
    "for dataset in data_dir_list:\n",
    "    img_list=os.listdir(data_path+'/'+ dataset)\n",
    "    print ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
    "    for img in img_list:\n",
    "        input_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
    "        input_img_resize=cv2.resize(input_img,(224,224))\n",
    "        img_data_list.append(input_img_resize)\n",
    "        labels_list.append(dataset)\n",
    "\n",
    "img_data = np.array(img_data_list)\n",
    "img_data = img_data.astype('float32')\n",
    "print (img_data.shape)\n",
    "\n",
    "print (np.mean(img_data))\n",
    "print (np.std(img_data))\n",
    "\n",
    "print (img_data.mean(axis=0))\n",
    "print (img_data.std(axis=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1620, 224, 224, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_samples = img_data.shape[0]\n",
    "labels = np.ones((num_of_samples,),dtype='int64')\n",
    "for i in range(0,num_classes):\n",
    "    labels[i*10:(i+1)*10]=i\n",
    "\n",
    "names = data_dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "Y = np_utils.to_categorical(labels, num_classes)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1296, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(img_data, Y, test_size=0.2, random_state=2)\n",
    "print(X_train.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unitiliser ResNet en le r√©entrainant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import resnet50\n",
    "from keras.applications.resnet import ResNet50\n",
    "from keras.applications.resnet import preprocess_input, decode_predictions\n",
    "\n",
    "# Import load image from keras.utils\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "\n",
    "# Import Model from keras.models\n",
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "41/41 [==============================] - 275s 7s/step - loss: 3.2585 - accuracy: 0.5301 - val_loss: 0.2551 - val_accuracy: 0.9784\n",
      "Epoch 2/5\n",
      "41/41 [==============================] - 246s 6s/step - loss: 0.0483 - accuracy: 0.9985 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "41/41 [==============================] - 251s 6s/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "41/41 [==============================] - 244s 6s/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "41/41 [==============================] - 267s 7s/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x161c95240>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the ResNet50 model\n",
    "resnet_model = ResNet50(weights='imagenet')\n",
    "\n",
    "# Change the last layer of the model\n",
    "x = resnet_model.layers[-2].output\n",
    "predictions = Dense(162, activation='softmax')(x)\n",
    "model = Model(inputs=resnet_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze all the layers except the last 4 layers\n",
    "for layer in model.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=5, verbose=1, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model \n",
    "model.save('model_resnet.h5')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 249ms/step\n",
      "Viktor\n",
      "Ahri\n",
      "Zoe\n",
      "Jayce\n",
      "Fiora\n"
     ]
    }
   ],
   "source": [
    "# Predict champ2.jpg (resize it to 224x224)\n",
    "img = load_img('./champ5.jpg', target_size=(224, 224))\n",
    "img = img_to_array(img)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img = preprocess_input(img)\n",
    "\n",
    "# Predict the class\n",
    "pred = model.predict(img)\n",
    "# take the 5 most probable classes\n",
    "pred = np.argsort(pred[0])[-5:]\n",
    "# name of the 5 most probable classes\n",
    "for i in pred:\n",
    "    print(names[i])\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TP1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "97c892bb3c077c71a79e73100b36200d50adffbda6aedb9a1044fd256d6aacf2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
